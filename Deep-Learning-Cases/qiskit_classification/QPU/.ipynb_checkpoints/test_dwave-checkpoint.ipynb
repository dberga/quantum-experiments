{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2086061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_ext autoreload\n",
    "#autoreload 2\n",
    "import numpy as np\n",
    "import glob\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from quantum_SVM import *   # QA SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec23f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputpath='output/run_calibtrain'\n",
    "maxalphas=20 # the 20 lowest-energy results returned by the quantum annealer are stored, but for the evaluation, we can consider less and compare\n",
    "\n",
    "# Parameters \n",
    "Bs=[2,3] #[2,3,5,10]                      Base\n",
    "Ks=[2] #[2,3]                             Number of qubits\n",
    "xis=[0,1,5] #[0,1,5]                      Strength to consider the constraint\n",
    "gammas=[-1] #[-1,0.125,0.25,0.5,1,2,4,8]  Kernel\n",
    "Es=[0,1,2] #[0,1,2]                       Exponent\n",
    "annealing_times=[1,10,100]\n",
    "chain_strengths=[0.2,0.5,1,2,5]\n",
    "embeddings=[0,1,2,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "515ee431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Dataset partitions: ['train', 'test']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../..'))\n",
    "from quantic.data import DatasetLoader\n",
    "\n",
    "# network args\n",
    "n_classes = 2\n",
    "n_qubits = 2\n",
    "n_features = None\n",
    "if n_features is None:\n",
    "    n_features = n_qubits\n",
    "# train args\n",
    "batch_size = 1\n",
    "epochs = 10\n",
    "LR = 0.001\n",
    "n_samples_train = 100\n",
    "n_samples_test = 50\n",
    "# dataset args\n",
    "shuffle = True\n",
    "specific_classes_names = []\n",
    "use_specific_classes = len(specific_classes_names)>=n_classes\n",
    "dataset = \"CIFAR10\"\n",
    "dataset_cfg = \"\"\n",
    "print(specific_classes_names)\n",
    "\n",
    "######## PREPARE DATASETS\n",
    "\n",
    "# Train Dataset\n",
    "# -------------\n",
    "\n",
    "if dataset_cfg:\n",
    "    # Load a dataset configuration file\n",
    "    dataset = DatasetLoader.load(from_cfg=dataset_cfg,framework='torchvision')\n",
    "else:\n",
    "    # Or instantate dataset manually\n",
    "    dataset = DatasetLoader.load(dataset_type=dataset,\n",
    "                                   num_classes=n_classes,\n",
    "                                   specific_classes=specific_classes_names,\n",
    "                                   num_samples_class_train=n_samples_train,\n",
    "                                   num_samples_class_test=n_samples_test,\n",
    "                                   framework='torchvision'\n",
    "                                   )\n",
    "print(f'Dataset partitions: {dataset.get_partitions()}')\n",
    "\n",
    "X_train = dataset['train']\n",
    "X_test = dataset['test']\n",
    "\n",
    "classes_str = \",\".join(dataset.specific_classes_names)\n",
    "classes2spec = {}\n",
    "specific_classes = dataset.specific_classes\n",
    "for idx, class_idx in enumerate(specific_classes):\n",
    "    classes2spec[class_idx]=idx\n",
    "\n",
    "classes_list = dataset.classes\n",
    "n_samples = n_samples_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a895056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.data = X_train.data.reshape(X_train.data.shape[0],X_train.data.shape[1]*X_train.data.shape[2]*X_train.data.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7cabff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting nodes and couplers\n",
      "Saving 400 nodes and 19832 couplers for output/run_calibtrain_B=2_K=2_xi=0_E=0_gamma=-1.0/\n",
      "running output/run_calibtrain_B=2_K=2_xi=0_E=0_gamma=-1.0/result_couplers=7500/ with 400 nodes and 7500 couplers for embedding [0, 1, 2, 3]\n",
      "Running chain strength 0.2 and annealing time 1\n",
      "\n",
      " -- no embedding found, removing output/run_calibtrain_B=2_K=2_xi=0_E=0_gamma=-1.0/result_couplers=7500/ and trying less couplers\n",
      "running output/run_calibtrain_B=2_K=2_xi=0_E=0_gamma=-1.0/result_couplers=5000/ with 400 nodes and 5000 couplers for embedding [0, 1, 2, 3]\n",
      "Running chain strength 0.2 and annealing time 1\n",
      "\n",
      " -- no embedding found, removing output/run_calibtrain_B=2_K=2_xi=0_E=0_gamma=-1.0/result_couplers=5000/ and trying less couplers\n",
      "running output/run_calibtrain_B=2_K=2_xi=0_E=0_gamma=-1.0/result_couplers=2500/ with 400 nodes and 2500 couplers for embedding [0, 1, 2, 3]\n",
      "Running chain strength 0.2 and annealing time 1\n",
      "\n",
      " -- no embedding found, removing output/run_calibtrain_B=2_K=2_xi=0_E=0_gamma=-1.0/result_couplers=2500/ and trying less couplers\n",
      "running output/run_calibtrain_B=2_K=2_xi=0_E=0_gamma=-1.0/result_couplers=2000/ with 400 nodes and 2000 couplers for embedding [0, 1, 2, 3]\n",
      "Running chain strength 0.2 and annealing time 1\n",
      "\n",
      " -- no embedding found, removing output/run_calibtrain_B=2_K=2_xi=0_E=0_gamma=-1.0/result_couplers=2000/ and trying less couplers\n",
      "running output/run_calibtrain_B=2_K=2_xi=0_E=0_gamma=-1.0/result_couplers=1800/ with 400 nodes and 1800 couplers for embedding [0, 1, 2, 3]\n",
      "Running chain strength 0.2 and annealing time 1\n",
      "\n",
      " -- no embedding found, removing output/run_calibtrain_B=2_K=2_xi=0_E=0_gamma=-1.0/result_couplers=1800/ and trying less couplers\n"
     ]
    },
    {
     "ename": "DisconnectedChainError",
     "evalue": "chain for 209 is not connected",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDisconnectedChainError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m path \u001b[38;5;241m=\u001b[39m outputpath\u001b[38;5;241m+\u001b[39msubpath\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m gen_svm_qubos(X_train\u001b[38;5;241m.\u001b[39mdata,X_train\u001b[38;5;241m.\u001b[39mtargets,B,K,xi,gamma,E,path)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mdwave_run_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mannealing_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchain_strengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mqpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/quantum-experiments-clone/qiskit_classification/QPU/quantum_SVM.py:99\u001b[0m, in \u001b[0;36mdwave_run_embedding\u001b[0;34m(data, label, path_in, annealing_times, chain_strengths, em_id, solver)\u001b[0m\n\u001b[1;32m     97\u001b[0m     embedding_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28meval\u001b[39m(embedding_file\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m     98\u001b[0m     embedding_file\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m---> 99\u001b[0m     \u001b[43msampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fix_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrunning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathsub\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(qubo_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m nodes and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcouplers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m couplers for embedding \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mem_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    102\u001b[0m ordering \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(BinaryQuadraticModel\u001b[38;5;241m.\u001b[39mfrom_qubo(Q)\u001b[38;5;241m.\u001b[39mvariables)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/dwave/system/composites/embedding.py:426\u001b[0m, in \u001b[0;36mLazyFixedEmbeddingComposite._fix_embedding\u001b[0;34m(self, embedding)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fix_embedding\u001b[39m(\u001b[38;5;28mself\u001b[39m, embedding):\n\u001b[1;32m    425\u001b[0m     target_edgelist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_structure\u001b[38;5;241m.\u001b[39medgelist\n\u001b[0;32m--> 426\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[43mEmbeddedStructure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_edgelist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;66;03m# save the embedding and overwrite the find_embedding function\u001b[39;00m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m embedding\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/dwave/embedding/transforms.py:108\u001b[0m, in \u001b[0;36mEmbeddedStructure.__init__\u001b[0;34m(self, target_edges, embedding)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m u, emb_u \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(emb_u) \u001b[38;5;241m!=\u001b[39m disjoint_sets[u]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m--> 108\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m DisconnectedChainError(u)\n",
      "\u001b[0;31mDisconnectedChainError\u001b[0m: chain for 209 is not connected"
     ]
    }
   ],
   "source": [
    "# generate qubos and couplers (embeddings)\n",
    "# make sure you have signed up in dwavesys.com and registered your computer 'dwave config create' with profile (login) and api key\n",
    "# https://cloud.dwavesys.com/leap/login/\n",
    "for B in Bs:\n",
    "    for K in Ks:\n",
    "        for gamma in gammas:\n",
    "            for xi in xis:\n",
    "                for E in Es:\n",
    "                    subpath=f\"_B={B}_K={K}_xi={xi}_E={E}_gamma={float(gamma)}\"\n",
    "                    path = outputpath+subpath+\"/\"\n",
    "                    gen_svm_qubos(X_train.data,X_train.targets,B,K,xi,gamma,E,path)\n",
    "                    dwave_run_embedding(X_train.data,X_train.targets,path,annealing_times,chain_strengths,embeddings,solver={'qpu': True}) #solver='Advantage_system1.1' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f291cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = colors.ListedColormap(['black', 'red'])\n",
    "plt.title('Prediction')\n",
    "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "Y_train_bin=np.where(Y_train==-1,0,Y_train)\n",
    "\n",
    "for B in Bs:\n",
    "    for K in Ks:\n",
    "        for gamma in gammas:\n",
    "            for xi in xis:\n",
    "                for E in Es:\n",
    "                    dirs=glob.glob(outputpath+f'_B={B}_K={K}_xi={xi}_E={E}_gamma={gamma}/result_couplers=*')\n",
    "                    if not dirs:\n",
    "                        dirs=glob.glob(outputpath+f'_B={B}_K={K}_xi={xi}_E={E}_gamma={float(gamma)}/result_couplers=*')\n",
    "                    if len(dirs) == 0:\n",
    "                        break\n",
    "                    path=dirs[0]+'/'\n",
    "                    f = open(path+f'collected_data_all_embeddings_maxalphas{maxalphas}.txt',\"w\") \n",
    "                    f.write(\"#rcs \\tt_a \\t trainacc\\t trainF1score\\t testacc\\t testF1score\\t average energy(train)\\n\") \n",
    "                    for emb in embeddings:\n",
    "                        for c in chain_strengths:\n",
    "                            for t in annealing_times:\n",
    "                                alphas=np.load(path+f'embedding{emb}_rcs{c}_ta{t}_alphas.npy')\n",
    "                                if not maxalphas == 0 or maxalphas > len(alphas):\n",
    "                                    alphas = alphas[0:maxalphas]\n",
    "\n",
    "                                scores_train=predict(X_train,X_train,Y_train,alphas,path)\n",
    "                                Y_predict_train=np.sign(scores_train)\n",
    "                                Y_predict_train=np.where(Y_predict_train==-1,0,Y_predict_train)\n",
    "                                Y_predict_train=np.where(Y_predict_train==1,1,Y_predict_train)\n",
    "\n",
    "                                scores=predict(X_test,X_train,Y_train,alphas,path)\n",
    "                                Y_predict=np.sign(scores)\n",
    "                                Y_predict=np.where(Y_predict==-1,0,Y_predict)   # From -1 to 0\n",
    "                                Y_predict=np.where(Y_predict==1,1,Y_predict)    # From -1 to 1\n",
    "        \n",
    "                                trainacc = accuracy_score(Y_train_bin[:], Y_predict_train)\n",
    "                                trainF1score = f1_score(Y_train_bin[:], Y_predict_train)\n",
    "                                testacc = accuracy_score(Y_test[:], Y_predict)\n",
    "                                testF1score = f1_score(Y_test[:], Y_predict)\n",
    "                                alphas_avg = np.mean(alphas,axis=0)\n",
    "                                av_energy = compute_energy(alphas_avg,X_train,Y_train,gamma,xi)\n",
    "                \n",
    "                                f.write(f'{c:1.2f}\\t {t:4}\\t {trainacc:8.4f}\\t{trainF1score:8.4f}\\t{testacc:8.4f}\\t{testF1score:8.4f}\\t{av_energy:8.4f}')\n",
    "                                f.write(\"\\n\")\n",
    "\n",
    "                                #  Visualize the prediction only for reasonable solutions\n",
    "                                if testacc > 0.75 and testF1score > 0.7: \n",
    "                                    print(f'B = {B}, K = {K}, gamma = {gamma}, xi = {xi}, E = {E},\\n  embedding {emb}, annealing time = {t}, rel. chain strength = {c}')\n",
    "                                    #print('On train data:')\n",
    "                                    #print ('Overal accuracy',trainacc)\n",
    "                                    #print ('F1 score',trainF1score)\n",
    "                                    print('Energy',av_energy)\n",
    "                                    print('On test data')\n",
    "                                    print ('Overal accuracy',testacc)\n",
    "                                    print ('F1 score',testF1score)\n",
    "                                    classification_map=np.reshape(Y_predict,(500,500))\n",
    "                                    plt.imshow(classification_map, cmap=cmap)\n",
    "                                    plt.clim(0, 1)\n",
    "                                    plt.show()\n",
    "                \n",
    "                            f.write(\"\\n\")\n",
    "                        f.write(\"\\n\")\n",
    "                    f.close()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
