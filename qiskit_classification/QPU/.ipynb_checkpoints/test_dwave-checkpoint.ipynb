{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2086061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_ext autoreload\n",
    "#autoreload 2\n",
    "import numpy as np\n",
    "import glob\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from quantum_SVM import *   # QA SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec23f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputpath='output/run_calibtrain'\n",
    "maxalphas=20 # the 20 lowest-energy results returned by the quantum annealer are stored, but for the evaluation, we can consider less and compare\n",
    "\n",
    "# Parameters \n",
    "Bs=[2,3] #[2,3,5,10]                      Base\n",
    "Ks=[2] #[2,3]                             Number of qubits\n",
    "xis=[0,1,5] #[0,1,5]                      Strength to consider the constraint\n",
    "gammas=[-1] #[-1,0.125,0.25,0.5,1,2,4,8]  Kernel\n",
    "Es=[0,1,2] #[0,1,2]                       Exponent\n",
    "annealing_times=[1,10,100]\n",
    "chain_strengths=[0.2,0.5,1,2,5]\n",
    "embeddings=[0,1,2,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515ee431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../..'))\n",
    "from quantic.data import DatasetLoader\n",
    "\n",
    "# network args\n",
    "n_classes = 2\n",
    "n_qubits = 2\n",
    "n_features = None\n",
    "if n_features is None:\n",
    "    n_features = n_qubits\n",
    "# train args\n",
    "batch_size = 1\n",
    "epochs = 10\n",
    "LR = 0.001\n",
    "n_samples_train = 100\n",
    "n_samples_test = 50\n",
    "# dataset args\n",
    "shuffle = True\n",
    "specific_classes_names = []\n",
    "use_specific_classes = len(specific_classes_names)>=n_classes\n",
    "dataset = \"CIFAR10\"\n",
    "dataset_cfg = \"\"\n",
    "print(specific_classes_names)\n",
    "\n",
    "######## PREPARE DATASETS\n",
    "\n",
    "# Train Dataset\n",
    "# -------------\n",
    "\n",
    "if dataset_cfg:\n",
    "    # Load a dataset configuration file\n",
    "    dataset = DatasetLoader.load(from_cfg=dataset_cfg,framework='torchvision')\n",
    "else:\n",
    "    # Or instantate dataset manually\n",
    "    dataset = DatasetLoader.load(dataset_type=dataset,\n",
    "                                   num_classes=n_classes,\n",
    "                                   specific_classes=specific_classes_names,\n",
    "                                   num_samples_class_train=n_samples_train,\n",
    "                                   num_samples_class_test=n_samples_test,\n",
    "                                   framework='torchvision'\n",
    "                                   )\n",
    "print(f'Dataset partitions: {dataset.get_partitions()}')\n",
    "\n",
    "X_train = dataset['train']\n",
    "X_test = dataset['test']\n",
    "\n",
    "classes_str = \",\".join(dataset.specific_classes_names)\n",
    "classes2spec = {}\n",
    "specific_classes = dataset.specific_classes\n",
    "for idx, class_idx in enumerate(specific_classes):\n",
    "    classes2spec[class_idx]=idx\n",
    "\n",
    "classes_list = dataset.classes\n",
    "n_samples = n_samples_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50beaeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.data = X_train.data.reshape(X_train.data.shape[0],X_train.data.shape[1]*X_train.data.shape[2]*X_train.data.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cabff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate qubos and couplers (embeddings)\n",
    "# make sure you have signed up in dwavesys.com and registered your computer 'dwave config create' with profile (login) and api key\n",
    "for B in Bs:\n",
    "    for K in Ks:\n",
    "        for gamma in gammas:\n",
    "            for xi in xis:\n",
    "                for E in Es:\n",
    "                    subpath=f\"_B={B}_K={K}_xi={xi}_E={E}_gamma={float(gamma)}\"\n",
    "                    path = outputpath+subpath+\"/\"\n",
    "                    gen_svm_qubos(X_train.data,X_train.targets,B,K,xi,gamma,E,path)\n",
    "                    dwave_run_embedding(X_train.data,X_train.targets,path,annealing_times,chain_strengths,embeddings,solver={'qpu': True}) #solver='Advantage_system1.1' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f291cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = colors.ListedColormap(['black', 'red'])\n",
    "plt.title('Prediction')\n",
    "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "Y_train_bin=np.where(Y_train==-1,0,Y_train)\n",
    "\n",
    "for B in Bs:\n",
    "    for K in Ks:\n",
    "        for gamma in gammas:\n",
    "            for xi in xis:\n",
    "                for E in Es:\n",
    "                    dirs=glob.glob(outputpath+f'_B={B}_K={K}_xi={xi}_E={E}_gamma={gamma}/result_couplers=*')\n",
    "                    if not dirs:\n",
    "                        dirs=glob.glob(outputpath+f'_B={B}_K={K}_xi={xi}_E={E}_gamma={float(gamma)}/result_couplers=*')\n",
    "                    if len(dirs) == 0:\n",
    "                        break\n",
    "                    path=dirs[0]+'/'\n",
    "                    f = open(path+f'collected_data_all_embeddings_maxalphas{maxalphas}.txt',\"w\") \n",
    "                    f.write(\"#rcs \\tt_a \\t trainacc\\t trainF1score\\t testacc\\t testF1score\\t average energy(train)\\n\") \n",
    "                    for emb in embeddings:\n",
    "                        for c in chain_strengths:\n",
    "                            for t in annealing_times:\n",
    "                                alphas=np.load(path+f'embedding{emb}_rcs{c}_ta{t}_alphas.npy')\n",
    "                                if not maxalphas == 0 or maxalphas > len(alphas):\n",
    "                                    alphas = alphas[0:maxalphas]\n",
    "\n",
    "                                scores_train=predict(X_train,X_train,Y_train,alphas,path)\n",
    "                                Y_predict_train=np.sign(scores_train)\n",
    "                                Y_predict_train=np.where(Y_predict_train==-1,0,Y_predict_train)\n",
    "                                Y_predict_train=np.where(Y_predict_train==1,1,Y_predict_train)\n",
    "\n",
    "                                scores=predict(X_test,X_train,Y_train,alphas,path)\n",
    "                                Y_predict=np.sign(scores)\n",
    "                                Y_predict=np.where(Y_predict==-1,0,Y_predict)   # From -1 to 0\n",
    "                                Y_predict=np.where(Y_predict==1,1,Y_predict)    # From -1 to 1\n",
    "        \n",
    "                                trainacc = accuracy_score(Y_train_bin[:], Y_predict_train)\n",
    "                                trainF1score = f1_score(Y_train_bin[:], Y_predict_train)\n",
    "                                testacc = accuracy_score(Y_test[:], Y_predict)\n",
    "                                testF1score = f1_score(Y_test[:], Y_predict)\n",
    "                                alphas_avg = np.mean(alphas,axis=0)\n",
    "                                av_energy = compute_energy(alphas_avg,X_train,Y_train,gamma,xi)\n",
    "                \n",
    "                                f.write(f'{c:1.2f}\\t {t:4}\\t {trainacc:8.4f}\\t{trainF1score:8.4f}\\t{testacc:8.4f}\\t{testF1score:8.4f}\\t{av_energy:8.4f}')\n",
    "                                f.write(\"\\n\")\n",
    "\n",
    "                                #  Visualize the prediction only for reasonable solutions\n",
    "                                if testacc > 0.75 and testF1score > 0.7: \n",
    "                                    print(f'B = {B}, K = {K}, gamma = {gamma}, xi = {xi}, E = {E},\\n  embedding {emb}, annealing time = {t}, rel. chain strength = {c}')\n",
    "                                    #print('On train data:')\n",
    "                                    #print ('Overal accuracy',trainacc)\n",
    "                                    #print ('F1 score',trainF1score)\n",
    "                                    print('Energy',av_energy)\n",
    "                                    print('On test data')\n",
    "                                    print ('Overal accuracy',testacc)\n",
    "                                    print ('F1 score',testF1score)\n",
    "                                    classification_map=np.reshape(Y_predict,(500,500))\n",
    "                                    plt.imshow(classification_map, cmap=cmap)\n",
    "                                    plt.clim(0, 1)\n",
    "                                    plt.show()\n",
    "                \n",
    "                            f.write(\"\\n\")\n",
    "                        f.write(\"\\n\")\n",
    "                    f.close()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
