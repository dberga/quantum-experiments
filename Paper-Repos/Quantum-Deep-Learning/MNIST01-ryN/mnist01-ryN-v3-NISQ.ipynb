{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- coding: utf-8 --\n",
    "# This code is part of Qiskit.\n",
    "#\n",
    "# (C) Copyright IBM 2019.\n",
    "#\n",
    "# This code is licensed under the Apache License, Version 2.0. You may\n",
    "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
    "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
    "#\n",
    "# Any modifications or derivative works of this code must retain this\n",
    "# copyright notice, and modified files need to carry a notice indicating\n",
    "# that they have been altered from the originals.\n",
    "#\n",
    "# Code adapted from QizGloria team, Qiskit Camp Europe 2019, updated by \n",
    "# Team Ube Pancake, Qiskit Summer Jam 2020\n",
    "#\n",
    "# WORKS for Quantum Circuit with variable number of qubits! Now supports running on GPU (CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device(\"cuda:0\")\n",
    "#     print(\"Running on the GPU\")\n",
    "# else:\n",
    "#     device = torch.device(\"cpu\")\n",
    "#     print(\"Running on the CPU\")\n",
    "    \n",
    "# torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import execute\n",
    "from qiskit.circuit import Parameter,ControlledGate\n",
    "from qiskit import Aer\n",
    "import qiskit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "configrc.store_credentials:WARNING:2020-07-01 00:24:45,118: Credentials already present. Set overwrite=True to overwrite.\n",
      "ibmqfactory.load_account:WARNING:2020-07-01 00:24:45,443: Credentials are already in use. The existing account in the session will be replaced.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from qiskit import IBMQ\n",
    "\n",
    "# Authenticate an account and add for use during this session. Replace string\n",
    "# argument with your private token.\n",
    "\n",
    "provider = IBMQ.load_account()\n",
    "backend = provider.get_backend('ibmq_rome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42\n",
    "\n",
    "NUM_QUBITS = 2\n",
    "NUM_SHOTS = 1000\n",
    "SHIFT = np.pi/2\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.5\n",
    "SIMULATOR = backend\n",
    "# SIMULATOR = Aer.get_backend('qasm_simulator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '01', '10', '11']\n"
     ]
    }
   ],
   "source": [
    "# create list of all possible outputs of quantum circuit (2**NUM_QUBITS possible)\n",
    "import itertools\n",
    "def create_QC_OUTPUTS():\n",
    "    measurements = list(itertools.product([0, 1], repeat=NUM_QUBITS))\n",
    "    return [''.join([str(bit) for bit in measurement]) for measurement in measurements]\n",
    "\n",
    "QC_OUTPUTS = create_QC_OUTPUTS()\n",
    "print(QC_OUTPUTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to translate Q-Circuit parameters from pytorch back to QISKIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Contruct QuantumCircuit Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T16:09:30.598730Z",
     "start_time": "2019-10-01T16:09:30.567861Z"
    }
   },
   "outputs": [],
   "source": [
    "class QiskitCircuit():\n",
    "    \n",
    "    def __init__(self, n_qubits, backend, shots):\n",
    "        # --- Circuit definition ---\n",
    "        self.circuit = qiskit.QuantumCircuit(n_qubits)\n",
    "        self.n_qubits = n_qubits\n",
    "        self.thetas ={k : Parameter('Theta'+str(k))for k in range(self.n_qubits)}\n",
    "        \n",
    "        all_qubits = [i for i in range(n_qubits)]\n",
    "        self.circuit.h(all_qubits)\n",
    "        self.circuit.barrier()\n",
    "        for k in range(n_qubits):\n",
    "            self.circuit.ry(self.thetas[k], k)\n",
    "        \n",
    "#         # Apply controlled-unitary\n",
    "# #         uc=ry(self.theta4, 4).to_gate().control(4)\n",
    "# #         self.circuit.append(uc, [0,1,2,3,4])\n",
    "#         self.circuit.ry(self.theta4, 4).to_gate().control(4)\n",
    "\n",
    "        self.circuit.measure_all()\n",
    "        # ---------------------------\n",
    "        \n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "        \n",
    "#             check = perc\n",
    "#             for i in range(nr_qubits):\n",
    "#                 check *= (float(key[i])-1/2)*2\n",
    "#             expects += check   \n",
    "        \n",
    "    def N_qubit_expectation_Z(self,counts, shots, nr_qubits):\n",
    "        expects = np.zeros(len(QC_OUTPUTS))\n",
    "        for k in range(len(QC_OUTPUTS)):\n",
    "            key = QC_OUTPUTS[k]\n",
    "            perc = counts.get(key, 0) /shots\n",
    "            expects[k] = perc\n",
    "        return expects\n",
    "    \n",
    "    def run(self, i):\n",
    "        params = i\n",
    "#         print('params = {}'.format(len(params)))\n",
    "        backend = SIMULATOR\n",
    "    \n",
    "        job_sim = execute(self.circuit,\n",
    "                              self.backend,\n",
    "                              shots=self.shots,\n",
    "                              parameter_binds = [{self.thetas[k] : params[k].item() for k in range(NUM_QUBITS)}])\n",
    "#         \n",
    "        result_sim = job_sim.result()\n",
    "        counts = result_sim.get_counts(self.circuit)\n",
    "        return self.N_qubit_expectation_Z(counts,self.shots,NUM_QUBITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected value for rotation [pi/4]: [0.041 0.152 0.147 0.66 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 539.392x204.68 with 1 Axes>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit = QiskitCircuit(NUM_QUBITS, SIMULATOR, NUM_SHOTS)\n",
    "print('Expected value for rotation [pi/4]: {}'.format(circuit.run(torch.Tensor([np.pi/4]*NUM_QUBITS))))\n",
    "circuit.circuit.draw(output='mpl', filename='Figures/{}-qubit circuit ryN.jpg'.format(NUM_QUBITS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TorchCircuit()\n",
    "\n",
    "A pytorch layer always has two functions. One for the forward pass and one for the backward pass. The forward pass simply takes the Quantum Circuits variational parameters from the previous pytorch layer and runs the circuit on the defined hardware (defined in `QiskitCircuit.run()`) and returns the measurements from the quantum hardware.\n",
    "These measurements will be the inputs of the next pytorch layer.\n",
    "\n",
    "The backward pass returns the gradients of the quantum circuit. In this case here it is finite difference.\n",
    "\n",
    "the `forward_tensor` is saved from the forward pass. So we just have to do one evaluation of the Q-Circuit in the backpass for the finite difference.\n",
    "\n",
    "The `gradient` variable here is as well hard coded to 3 parameters. This should be updated in the future and made more general.\n",
    "\n",
    "The loop `for k in range(len(input_numbers)):` goes through all the parameters (in this case 3), and shifts them by a small $\\epsilon$. Then it runs the circuit and takes the diefferences of the ouput for the parameters $\\Theta$ and $\\Theta + \\epsilon$. This is the finite difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchCircuit(Function):    \n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        if not hasattr(ctx, 'QiskitCirc'):\n",
    "            ctx.QiskitCirc = QiskitCircuit(NUM_QUBITS, SIMULATOR, shots=NUM_SHOTS)\n",
    "            \n",
    "        exp_value = ctx.QiskitCirc.run(i)\n",
    "        \n",
    "        result = torch.tensor([exp_value])\n",
    "        \n",
    "        \n",
    "        ctx.save_for_backward(result, i)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \n",
    "        forward_tensor, i = ctx.saved_tensors\n",
    "#         print('forward_tensor = {}'.format(forward_tensor))\n",
    "        input_numbers = i\n",
    "#         print('input_numbers = {}'.format(input_numbers))\n",
    "        gradients = torch.Tensor()\n",
    "        \n",
    "        for k in range(NUM_QUBITS):\n",
    "            shift_right = input_numbers.detach().clone()\n",
    "            shift_right[k] = shift_right[k] + SHIFT\n",
    "            shift_left = input_numbers.detach().clone()\n",
    "            shift_left[k] = shift_left[k] - SHIFT\n",
    "            \n",
    "#             print('shift_right = {}, shift_left = {}'.format(shift_right, shift_left))\n",
    "            \n",
    "            expectation_right = ctx.QiskitCirc.run(shift_right)\n",
    "            expectation_left  = ctx.QiskitCirc.run(shift_left)\n",
    "#             print('expectation_right = {}, \\nexpectation_left = {}'.format(expectation_right, expectation_left))\n",
    "            \n",
    "            gradient = torch.tensor([expectation_right]) - torch.tensor([expectation_left])\n",
    "            # rescale gradient\n",
    "#             gradient = gradient / torch.norm(gradient)\n",
    "#             print('gradient for k={}: {}'.format(k, gradient))\n",
    "            gradients = torch.cat((gradients, gradient.float()))\n",
    "            \n",
    "        result = torch.Tensor(gradients)\n",
    "#         print('gradients = {}'.format(result))\n",
    "#         print('grad_output = {}'.format(grad_output))\n",
    "\n",
    "        return (result.float() * grad_output.float()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 after quantum layer: tensor([[0.0270, 0.1310, 0.1510, 0.6910]], dtype=torch.float64,\n",
      "       grad_fn=<TorchCircuitBackward>)\n",
      "x.grad = tensor([0.2398, 0.0041])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([np.pi/4]*NUM_QUBITS, requires_grad=True)\n",
    "\n",
    "qc = TorchCircuit.apply\n",
    "y1 = qc(x)\n",
    "print('y1 after quantum layer: {}'.format(y1))\n",
    "y1 = nn.Linear(2**NUM_QUBITS,1)(y1.float())\n",
    "y1.backward()\n",
    "print('x.grad = {}'.format(x.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Quantum Circuit's Gradient Descent\n",
    "\n",
    "First, we want the \"neural net\" consisting of just the quantum circuit (with its 4 inputs and 4 outputs) and a linear layer (from 4 inputs to 1 output) that scales measurement 1 by 1, measurement 2 by 2, etc., until it converges to a target value (-1). So, we define a cost function where the cost is defined as the square distance from the target value.\n",
    "\n",
    "`x` is the initialization of the parameters. Here, every angle in the quantum circuit starts at $\\pi/4$. We should see that the loss eventually goes down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc = TorchCircuit.apply\n",
    "\n",
    "def cost(x):\n",
    "    target = -1\n",
    "    expval = qc(x)[0]\n",
    "    # simple linear layer: average all outputs of quantum layer\n",
    "#     print(expval)\n",
    "    val = sum([(i+1)*expval[i] for i in range(2**NUM_QUBITS)]) / 2**NUM_QUBITS\n",
    "#     print(val)\n",
    "    return torch.abs(val - target) ** 2, expval\n",
    "\n",
    "x = torch.tensor([-np.pi/4]*NUM_QUBITS, requires_grad=True)\n",
    "opt = torch.optim.Adam([x], lr=0.1)\n",
    "\n",
    "num_epoch = 20\n",
    "\n",
    "loss_list = []\n",
    "expval_list = []\n",
    "\n",
    "for i in tqdm(range(num_epoch)):\n",
    "# for i in range(num_epoch):\n",
    "    opt.zero_grad()\n",
    "    loss, expval = cost(x)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    loss_list.append(loss.item())\n",
    "    expval_list.append(expval)\n",
    "\n",
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST (0-1) Dataset\n",
    "\n",
    "**Training Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Concentrating on the first 100 samples\n",
    "n_samples = 150\n",
    "\n",
    "X_train = datasets.MNIST(root='./data', train=True, download=True,\n",
    "                         transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# Leaving only labels 0 and 1 \n",
    "idx = np.append(np.where(X_train.targets == 0)[0][:n_samples], \n",
    "                np.where(X_train.targets == 1)[0][:n_samples])\n",
    "\n",
    "X_train.data = X_train.data[idx]\n",
    "X_train.targets = X_train.targets[idx]\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(X_train, batch_size=1, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 200\n",
    "\n",
    "X_test = datasets.MNIST(root='./data', train=False, download=True,\n",
    "                        transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "idx = np.append(np.where(X_test.targets == 0)[0][n_samples:], \n",
    "                np.where(X_test.targets == 1)[0][n_samples:])\n",
    "\n",
    "X_test.data = X_test.data[idx]\n",
    "X_test.targets = X_test.targets[idx]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(X_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Network with Q-node\n",
    "\n",
    "This NN is  2 layers of ConvNN and a fully connected layer, with a Q-Node as a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, NUM_QUBITS)\n",
    "        self.qc = TorchCircuit.apply\n",
    "        self.qcsim = nn.Linear(NUM_QUBITS, 1)\n",
    "        self.fc3 = nn.Linear(1, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = np.pi*torch.tanh(x)\n",
    "        \n",
    "#         print('params to QC: {}'.format(x))\n",
    "\n",
    "        MODE = 'QC' # 'QC' or 'QC_sim'\n",
    "    \n",
    "        if MODE == 'QC': \n",
    "            x = qc(x[0]) # QUANTUM LAYER\n",
    "        \n",
    "        else:\n",
    "            x = self.qcsim(x)\n",
    "            \n",
    "#         print('output of QC = {}'.format(x))\n",
    "        \n",
    "#         # softmax rather than sigmoid\n",
    "#         x = self.fc3(x.float())\n",
    "#         print('output of Linear(1, 2): {}'.format(x))\n",
    "#         x = F.softmax(x, 1)\n",
    "\n",
    "        x = torch.sigmoid(x)\n",
    "        x = torch.cat((x, 1-x), -1)\n",
    "#         print(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def predict(self, x):\n",
    "        # apply softmax\n",
    "        pred = self.forward(x)\n",
    "#         print(pred)\n",
    "        ans = torch.argmax(pred[0]).item()\n",
    "        return torch.tensor(ans)\n",
    "    \n",
    "network = Net()#.to(device)\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.001)\n",
    "\n",
    "# optimizer = optim.Adam(network.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "loss_list = []\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         print(batch_idx)\n",
    "        optimizer.zero_grad()        \n",
    "        # Forward pass\n",
    "        output = network(data)\n",
    "        # Calculating loss\n",
    "        loss = loss_func(output, target)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Optimize the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(\n",
    "        100. * (epoch + 1) / epochs, loss_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title('Hybrid NN Training Convergence for {}-qubit'.format(NUM_QUBITS))\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.savefig('Figures/{}-qubit Loss Curve ryN.jpg'.format(NUM_QUBITS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy of NN\n",
    "\n",
    "The outcome is not always the same because the prediction is probabilistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "number = 0\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    number +=1\n",
    "    output = network.predict(data).item()\n",
    "    accuracy += (output == target[0].item())*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance on test data is is: {}/{} = {}%\".format(accuracy,number,100*accuracy/number))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_shape = (8, 6)\n",
    "count = 0\n",
    "fig, axes = plt.subplots(nrows=n_samples_shape[0], ncols=n_samples_shape[1], figsize=(10, 2*n_samples_shape[0]))\n",
    "\n",
    "network.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if count == n_samples_shape[0]*n_samples_shape[1]:\n",
    "            break\n",
    "        pred = network.predict(data).item()\n",
    "\n",
    "        axes[count//n_samples_shape[1]][count%n_samples_shape[1]].imshow(data[0].numpy().squeeze(), cmap='gray')\n",
    "\n",
    "        axes[count//n_samples_shape[1]][count%n_samples_shape[1]].set_xticks([])\n",
    "        axes[count//n_samples_shape[1]][count%n_samples_shape[1]].set_yticks([])\n",
    "        axes[count//n_samples_shape[1]][count%n_samples_shape[1]].set_title('Predicted {}'.format(pred))\n",
    "        \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
